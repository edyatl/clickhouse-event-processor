{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec5f735-556a-4532-b51c-a77771f146b5",
   "metadata": {},
   "source": [
    "## ClickHouse Event Monitoring and GET Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa54f832-d4c9-4b7c-b4f1-6da6e7efbdad",
   "metadata": {},
   "source": [
    "> Developed by [@edyatl](https://github.com/edyatl) January 2024 <edyatl@yandex.ru>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb823a1f-e15a-4f1a-9bfb-ffa277bef91c",
   "metadata": {},
   "source": [
    "**Update 2024-02-14:** when the *af_start_trial* event arrives, we wait 1 hour from *event_time* and if a new *trial_renewal_cancelled* event arrives for the same id (af_sub1), then we do nothing, and if it doesnâ€™t arrive, then we send a get request as usual.\n",
    "\n",
    "**Update 2024-02-22:** Added GET requests for *trial_renewal_cancelled* event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d5a4f1-38ff-41a9-8cce-6a6df8f17d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Jupyter extension for auto correction coding style based on Black Lib\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c754ec-003b-4fe1-bf9c-991cf0706f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "# import sys\n",
    "\n",
    "# !{sys.executable} -m pip install -U pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c951373-0fd9-42c0-bc6b-fd36114a3154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "import json\n",
    "import sqlite3 as sql\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "import clickhouse_connect\n",
    "\n",
    "from config import Configuration as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a0dee9-9262-4749-aac3-039d8294d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cls_logger(cls: str) -> object:\n",
    "    \"\"\"\n",
    "    Logger config. Sets handler to a file, formater and logging level.\n",
    "\n",
    "    :param cls:\n",
    "        str Name of class where logger calling.\n",
    "    :return:\n",
    "        Returns Logger instans.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(cls)\n",
    "    if not logger.handlers:\n",
    "        handler = logging.FileHandler(cfg.LOG_FILE)\n",
    "        formatter = logging.Formatter(\n",
    "            \"%(asctime)s %(name)-16s [%(levelname)s] %(message)s\", \"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "    logger.setLevel(logging.DEBUG if cfg.DEBUG else logging.INFO)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789d4740-d428-4185-a246-be1032143415",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClickHouseConnector:\n",
    "    \"\"\"Class to connect ClickHouse DWH and fetch events.\"\"\"\n",
    "\n",
    "    logger = get_cls_logger(__qualname__)\n",
    "    json_file_path = cfg.JSON_FILE\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Constructor func, gets credentials and makes an instance.\n",
    "        \"\"\"\n",
    "        self.host = kwargs.get(\"host\") or \"\"\n",
    "        self.user = kwargs.get(\"user\") or \"\"\n",
    "        self.password = kwargs.get(\"password\") or \"\"\n",
    "        self.port = kwargs.get(\"port\") or \"\"\n",
    "\n",
    "        self.client = clickhouse_connect.get_client(\n",
    "            host=self.host, user=self.user, password=self.password, port=self.port\n",
    "        )\n",
    "\n",
    "        self.query_cnt = \"\"\"SELECT count()\n",
    "            FROM analytics.appsflyer_export \n",
    "            WHERE media_source = 'Popunder'\n",
    "            AND event_name IN ('install', 'af_start_trial', 'af_subscribe', 'trial_renewal_cancelled')\"\"\"\n",
    "\n",
    "        self.query_str = \"\"\"SELECT event_time,event_name,af_sub1\n",
    "            FROM analytics.appsflyer_export \n",
    "            WHERE media_source = 'Popunder'\n",
    "            AND event_name IN ('install', 'af_start_trial', 'af_subscribe', 'trial_renewal_cancelled')\n",
    "            ORDER BY event_time DESC\n",
    "            LIMIT {dev:int}\"\"\"\n",
    "\n",
    "        # Check if the JSON file exists\n",
    "        if os.path.exists(self.json_file_path):\n",
    "            # Read the existing JSON file\n",
    "            with open(self.json_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                stored_values = json.load(file)\n",
    "                self.prev_rows_number = stored_values.get(\"prev_rows_number\", 0)\n",
    "        else:\n",
    "            self.prev_rows_number = 0\n",
    "        self.logger.debug(\"Make an instance of %s class\", self.__class__.__name__)\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"\n",
    "        Destructor func, closes connection.\n",
    "        \"\"\"\n",
    "        self.client.close()\n",
    "\n",
    "    def fetch_new_events(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Fetches new events from ClickHouse DWH.\n",
    "        \"\"\"\n",
    "        cnt = int(self.client.command(self.query_cnt))\n",
    "        dev = cnt - self.prev_rows_number\n",
    "        if dev == 0:\n",
    "            return pd.DataFrame()\n",
    "        parameters = {\"dev\": dev}\n",
    "        result = self.client.query(self.query_str, parameters=parameters)\n",
    "        with open(self.json_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            json.dump({\"prev_rows_number\": cnt}, file)\n",
    "        return pd.DataFrame(result.result_rows, columns=result.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f287f-e3a5-4aaa-b943-1da6b98b626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventProcessor:\n",
    "    \"\"\"Class for processing events.\"\"\"\n",
    "\n",
    "    BASE_URL = cfg.BASE_URL\n",
    "    logger = get_cls_logger(__qualname__)\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Constructor func, gets events DataFrame and makes an instance.\n",
    "        Trying to connect db or creating it if not exists.\n",
    "        \"\"\"\n",
    "        self.events_df = kwargs.get(\"events\")\n",
    "        self.install = self.events_df[self.events_df[\"event_name\"] == \"install\"]\n",
    "        self.trial = self.events_df[self.events_df[\"event_name\"] == \"af_start_trial\"]\n",
    "        self.trial_cancelled = self.events_df[\n",
    "            self.events_df[\"event_name\"] == \"trial_renewal_cancelled\"\n",
    "        ]\n",
    "        self.activation = self.events_df[self.events_df[\"event_name\"] == \"af_subscribe\"]\n",
    "        self.logger.debug(\"Make an instance of %s class\", self.__class__.__name__)\n",
    "\n",
    "        with sql.connect(cfg.DB_FILE, timeout=10) as con:\n",
    "            db = con.cursor()\n",
    "\n",
    "            try:\n",
    "                self.logger.debug(\"Try to connect sqlite db\")\n",
    "                db.execute(\"SELECT id FROM cachetab\")\n",
    "            except sql.OperationalError:\n",
    "                self.logger.debug(\"Sqlite db not exists, creating it from schema\")\n",
    "                db.executescript(open(cfg.SCHEMA_FILE, \"rt\", encoding=\"utf-8\").read())\n",
    "\n",
    "    def requests_call(self, verb: str, url: str, params=None, **kwargs) -> tuple:\n",
    "        \"\"\"\n",
    "        Wraping func for requests with errors handling.\n",
    "\n",
    "        :param verb:\n",
    "            str Method of request ``get`` or ``post``.\n",
    "        :param url:\n",
    "            str URL to connect.\n",
    "        :return:\n",
    "            Returns a tuple of response object and error.\n",
    "            If an error occurs, the response will be empty\n",
    "            and vice versa otherwise.\n",
    "        \"\"\"\n",
    "        r: object = None\n",
    "        error: str = None\n",
    "        retries: int = cfg.RETRIES  # default 10\n",
    "        delay: int = cfg.DELAY  # default 6\n",
    "\n",
    "        for retry in range(retries):\n",
    "            try:\n",
    "                self.logger.debug(\"Try %s request %s\", verb, url)\n",
    "                r = requests.request(verb, url, params=params)\n",
    "                r.raise_for_status()\n",
    "                self.logger.debug(\n",
    "                    \"Get answer with status code: %s %s\", r.status_code, r.reason\n",
    "                )\n",
    "                return r, error\n",
    "            except requests.exceptions.HTTPError as errh:\n",
    "                self.logger.error(\"Http Error: %s\", errh)\n",
    "                error = errh\n",
    "                self.logger.debug(\n",
    "                    \"Don't give up! Trying to reconnect, retry %s of %s\",\n",
    "                    retry + 1,\n",
    "                    retries,\n",
    "                )\n",
    "                time.sleep(delay)\n",
    "            except requests.exceptions.ConnectionError as errc:\n",
    "                self.logger.error(\"Connection Error: %s\", errc)\n",
    "                error = errc\n",
    "                self.logger.debug(\n",
    "                    \"Don't give up! Trying to reconnect, retry %s of %s\",\n",
    "                    retry + 1,\n",
    "                    retries,\n",
    "                )\n",
    "                time.sleep(delay)\n",
    "            except requests.exceptions.Timeout as errt:\n",
    "                self.logger.error(\"Timeout Error: %s\", errt)\n",
    "                error = errt\n",
    "                self.logger.debug(\n",
    "                    \"Don't give up! Trying to reconnect, retry %s of %s\",\n",
    "                    retry + 1,\n",
    "                    retries,\n",
    "                )\n",
    "                time.sleep(delay)\n",
    "            except requests.exceptions.RequestException as err:\n",
    "                self.logger.error(\"OOps: Unexpected Error: %s\", err)\n",
    "                error = err\n",
    "                self.logger.debug(\n",
    "                    \"Don't give up! Trying to reconnect, retry %s of %s\",\n",
    "                    retry + 1,\n",
    "                    retries,\n",
    "                )\n",
    "                time.sleep(delay)\n",
    "\n",
    "        return r, error\n",
    "\n",
    "    # Functon for saving trials to cache db\n",
    "    def save_trials_to_db(\n",
    "        self, event_time: datetime, event_name: str, af_sub1: str\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Save events to cache db.\n",
    "        \"\"\"\n",
    "        payload = {\n",
    "            \"date\": datetime.datetime.now(),\n",
    "            \"event_time\": event_time,\n",
    "            \"event_name\": event_name,\n",
    "            \"af_sub1\": af_sub1,\n",
    "        }\n",
    "\n",
    "        with sql.connect(cfg.DB_FILE, timeout=10) as con:\n",
    "            db = con.cursor()\n",
    "            db.execute(\"SELECT id FROM cachetab WHERE af_sub1=:af_sub1\", payload)\n",
    "\n",
    "            if len(db.fetchall()) == 0:\n",
    "                db.execute(\n",
    "                    \"INSERT INTO cachetab (date, event_time, event_name, af_sub1)\"\n",
    "                    \"values (:date, :event_time, :event_name, :af_sub1)\",\n",
    "                    payload,\n",
    "                )\n",
    "                try:\n",
    "                    con.commit()\n",
    "                    self.logger.debug(\n",
    "                        \"New record (%s) inserted in db\", payload[\"af_sub1\"]\n",
    "                    )\n",
    "                except sql.OperationalError as err:\n",
    "                    self.logger.error(\"OOps: Operational Error: %s\", err)\n",
    "                    return\n",
    "            else:\n",
    "                self.logger.warning(\"Record has already in db, skipping\")\n",
    "\n",
    "    # Function for removing trials from cache db by af_sub1\n",
    "    def remove_trials_from_db(self, af_sub1: str) -> None:\n",
    "        \"\"\"\n",
    "        Remove events from cache db.\n",
    "        \"\"\"\n",
    "        with sql.connect(cfg.DB_FILE, timeout=10) as con:\n",
    "            db = con.cursor()\n",
    "            db.execute(\n",
    "                \"DELETE FROM cachetab WHERE af_sub1=:af_sub1\", {\"af_sub1\": af_sub1}\n",
    "            )\n",
    "            try:\n",
    "                con.commit()\n",
    "                self.logger.debug(\"Record (%s) removed from db\", af_sub1)\n",
    "            except sql.OperationalError as err:\n",
    "                self.logger.error(\"OOps: Operational Error: %s\", err)\n",
    "                return\n",
    "\n",
    "    # Process new trials and save them to db\n",
    "    def process_new_trials(self):\n",
    "        \"\"\"\n",
    "        Process new trials and save them to db.\n",
    "        \"\"\"\n",
    "        if self.trial.shape[0] == 0:\n",
    "            return\n",
    "        for index, row in self.trial.iterrows():\n",
    "            self.save_trials_to_db(row[\"event_time\"], row[\"event_name\"], row[\"af_sub1\"])\n",
    "\n",
    "    # Process cancelled trials and remove them from db\n",
    "    def process_cancelled_trials(self):\n",
    "        \"\"\"\n",
    "        Process cancelled trials and remove them from db.\n",
    "        \"\"\"\n",
    "        if self.trial_cancelled.shape[0] == 0:\n",
    "            return\n",
    "        for index, row in self.trial_cancelled.iterrows():\n",
    "            self.remove_trials_from_db(row[\"af_sub1\"])\n",
    "\n",
    "    # Function gets trials from cache db where event_time <= now - 1 hour. Returns pandas DataFrame.\n",
    "    def get_trials_from_db(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get events from cache db.\n",
    "        \"\"\"\n",
    "        with sql.connect(cfg.DB_FILE, timeout=10) as con:\n",
    "            db = con.cursor()\n",
    "            db.execute(\n",
    "                \"\"\"SELECT date, event_time, event_name, af_sub1 FROM cachetab\n",
    "                WHERE event_name = 'af_start_trial' AND event_time <= datetime('now', '-1 hour')\"\"\"\n",
    "            )\n",
    "            return pd.DataFrame(\n",
    "                db.fetchall(), columns=[\"date\", \"event_time\", \"event_name\", \"af_sub1\"]\n",
    "            )\n",
    "\n",
    "    def install_requests(self):\n",
    "        \"\"\"\n",
    "        Send requests for install events.\n",
    "        \"\"\"\n",
    "        if self.install.shape[0] == 0:\n",
    "            return\n",
    "        url = self.BASE_URL\n",
    "        for af_sub1 in self.install[\"af_sub1\"]:\n",
    "            params = [\n",
    "                [\"cnv_id\", af_sub1],\n",
    "                [\"cnv_status\", \"install\"],\n",
    "                [\"event1\", 1],\n",
    "            ]\n",
    "            response, error = self.requests_call(\"GET\", url=url, params=params)\n",
    "\n",
    "    # Function confirmed_trial_requests for sending requests for trial events.\n",
    "    # Gets DataFrame from get_trials_from_db then sends GET requests and then\n",
    "    # deletes from db processed trials.\n",
    "    def confirmed_trial_requests(self):\n",
    "        \"\"\"\n",
    "        Send requests for trial events.\n",
    "        \"\"\"\n",
    "        df = self.get_trials_from_db()\n",
    "        if df.empty:\n",
    "            return\n",
    "        url = self.BASE_URL\n",
    "        for af_sub1 in df[\"af_sub1\"]:\n",
    "            params = [\n",
    "                [\"cnv_id\", af_sub1],\n",
    "                [\"cnv_status\", \"trial_started\"],\n",
    "                [\"event2\", 1],\n",
    "            ]\n",
    "            response, error = self.requests_call(\"GET\", url=url, params=params)\n",
    "            if error is not None:\n",
    "                self.logger.error(\"Error: %s\", error)\n",
    "                continue\n",
    "            self.logger.debug(\"Request sent: %s\", response)\n",
    "            self.remove_trials_from_db(af_sub1)\n",
    "\n",
    "    def trial_requests(self):\n",
    "        \"\"\"\n",
    "        Send requests for trial events.\n",
    "        \"\"\"\n",
    "        if self.trial.shape[0] == 0:\n",
    "            return\n",
    "        url = self.BASE_URL\n",
    "        for af_sub1 in self.trial[\"af_sub1\"]:\n",
    "            params = [\n",
    "                [\"cnv_id\", af_sub1],\n",
    "                [\"cnv_status\", \"trial_started\"],\n",
    "                [\"event2\", 1],\n",
    "            ]\n",
    "            response, error = self.requests_call(\"GET\", url=url, params=params)\n",
    "\n",
    "    def activation_requests(self):\n",
    "        \"\"\"\n",
    "        Send requests for activation events.\n",
    "        \"\"\"\n",
    "        if self.activation.shape[0] == 0:\n",
    "            return\n",
    "        url = self.BASE_URL\n",
    "        for af_sub1 in self.activation[\"af_sub1\"]:\n",
    "            params = [\n",
    "                [\"cnv_id\", af_sub1],\n",
    "                [\"cnv_status\", \"trial_converted\"],\n",
    "                [\"event4\", 1],\n",
    "            ]\n",
    "            response, error = self.requests_call(\"GET\", url=url, params=params)\n",
    "\n",
    "    def cancel_trial_requests(self):\n",
    "        \"\"\"\n",
    "        Send requests for cancelled trial events.\n",
    "        \"\"\"\n",
    "        if self.trial_cancelled.shape[0] == 0:\n",
    "            return\n",
    "        url = self.BASE_URL\n",
    "        for af_sub1 in self.trial_cancelled['af_sub1']:\n",
    "            params = [\n",
    "                [\"cnv_id\", af_sub1],\n",
    "                [\"cnv_status\", \"trial_renewal_cancelled\"],\n",
    "                [\"event6\", 1],\n",
    "            ]\n",
    "            response, error = self.requests_call('GET', url=url, params=params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb664ef3-9cf5-484a-98ba-e01202b29afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwh = ClickHouseConnector(\n",
    "    host=cfg.CLICKHOUSE_HOST,\n",
    "    user=cfg.CLICKHOUSE_USER,\n",
    "    password=cfg.CLICKHOUSE_PASS,\n",
    "    port=cfg.CLICKHOUSE_PORT\n",
    ")\n",
    "\n",
    "df = dwh.fetch_new_events()\n",
    "\n",
    "del dwh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387f66e6-f79e-4fe2-8bec-8b0b764fd6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['event_name'] == 'af_start_trial']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08206e3a-9a16-4224-b72b-e9cfaa3556b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    evs = EventProcessor(events=df)\n",
    "    # evs.install_requests()\n",
    "    # evs.trial_requests()\n",
    "    # evs.activation_requests()\n",
    "    evs.process_new_trials()\n",
    "    evs.process_cancelled_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a99df57-9917-4b20-a3c9-a836ef58dd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "evs.trial.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aed26b-e4b8-4fc0-925e-6581e4576d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "evs.save_trials_to_db(evs.trial.iloc[0]['event_time'], evs.trial.iloc[0]['event_name'], evs.trial.iloc[0]['af_sub1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ad538e-b9f1-406d-a8c2-ec11a0cc2347",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in evs.trial.iterrows():\n",
    "    print(row['event_time'], row['event_name'], row['af_sub1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7923e459-5dab-4075-a664-4d3bf41a647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evs.get_trials_from_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc8b5dc-0ee9-4e07-a6a1-bd52b920dab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "evnts = EventProcessor(events=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c92c58b-1b38-44d3-bc4f-cbfa73d7e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evnts.events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00531dd-d6e9-4192-baa4-90d162643ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for af_sub1 in evnts.install['af_sub1']:\n",
    "    print(af_sub1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2bd154-290e-4f40-a024-7b8e43828b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = os.path.join(os.path.abspath(''), 'var_storage.json')\n",
    "prev_rows_number = 8\n",
    "\n",
    "with open(json_file_path, 'w') as file:\n",
    "    json.dump({'prev_rows_number': prev_rows_number}, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e126c8-00ac-45fc-875f-c21e2de3e163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
