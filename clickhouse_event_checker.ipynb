{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec5f735-556a-4532-b51c-a77771f146b5",
   "metadata": {},
   "source": [
    "## ClickHouse Event Monitoring and GET Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa54f832-d4c9-4b7c-b4f1-6da6e7efbdad",
   "metadata": {},
   "source": [
    "> Developed by [@edyatl](https://github.com/edyatl) January 2024 <edyatl@yandex.ru>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb823a1f-e15a-4f1a-9bfb-ffa277bef91c",
   "metadata": {},
   "source": [
    "**Update 2024-04-16:**\n",
    "- Designed the system to handle incoming events in batches of about 1000 items, ensuring efficient processing and scalability.\n",
    "- Implemented logic to handle partially duplicate events within each batch, ensuring that only new events not present in previous batches are processed further.\n",
    "- Developed a filtering mechanism to identify and extract only the new events from each batch, improving data integrity and reducing redundancy.\n",
    "- Integrated functionality to transmit the filtered events further using GET requests, ensuring seamless communication with external systems.\n",
    "- Canceled trials handling functionality has been permanently removed.\n",
    "\n",
    "**Update 2024-04-09:**\n",
    "- Implemented bypass of cancelled trials processing to ensure accurate event tracking.\n",
    "- Added functionality to set the secret path of the base URL in the configuration settings for enhanced security.\n",
    "- Introduced the `FINAL` instruction into SQL queries within the `FROM` section to retrieve ClickHouse rows without duplicates, optimizing data retrieval.\n",
    "- These updates enhance the reliability, security, and performance of the clickhouse_event_checker tool.\n",
    "\n",
    "**Update 2024-02-14:** when the *af_start_trial* event arrives, we wait 1 hour from *event_time* and if a new *trial_renewal_cancelled* event arrives for the same id (af_sub1), then we do nothing, and if it doesnâ€™t arrive, then we send a get request as usual.\n",
    "\n",
    "**Update 2024-02-22:** Added GET requests for *trial_renewal_cancelled* event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51d5a4f1-38ff-41a9-8cce-6a6df8f17d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"# Load Jupyter extension for auto correction coding style based on Black Lib\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"# Load Jupyter extension for auto correction coding style based on Black Lib\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Jupyter extension for auto correction coding style based on Black Lib\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76c754ec-003b-4fe1-bf9c-991cf0706f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Install a pip package in the current Jupyter kernel\\n# import sys\\n\\n# !{sys.executable} -m pip install -U dotenv\";\n",
       "                var nbb_formatted_code = \"# Install a pip package in the current Jupyter kernel\\n# import sys\\n\\n# !{sys.executable} -m pip install -U dotenv\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "# import sys\n",
    "\n",
    "# !{sys.executable} -m pip install -U dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c951373-0fd9-42c0-bc6b-fd36114a3154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"import os\\nimport time\\n\\nfrom datetime import datetime, timedelta\\nimport json\\nimport sqlite3 as sql\\nimport requests\\nimport pandas as pd\\n\\nimport clickhouse_connect\\n\\nfrom config import Configuration as cfg\";\n",
       "                var nbb_formatted_code = \"import os\\nimport time\\n\\nfrom datetime import datetime, timedelta\\nimport json\\nimport sqlite3 as sql\\nimport requests\\nimport pandas as pd\\n\\nimport clickhouse_connect\\n\\nfrom config import Configuration as cfg\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import sqlite3 as sql\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "import clickhouse_connect\n",
    "\n",
    "from config import Configuration as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "448a56d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"cfg.DEBUG = True\\nfrom logger import get_cls_logger\";\n",
       "                var nbb_formatted_code = \"cfg.DEBUG = True\\nfrom logger import get_cls_logger\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg.DEBUG = True\n",
    "from logger import get_cls_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7d81f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# !cat clickhouse_event_checker.py\";\n",
       "                var nbb_formatted_code = \"# !cat clickhouse_event_checker.py\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !cat clickhouse_event_checker.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad455250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class ClickHouseConnector:\\n    \\\"\\\"\\\"Class to connect ClickHouse DWH and fetch events.\\\"\\\"\\\"\\n\\n    logger = get_cls_logger(__qualname__)\\n    json_file_path = cfg.JSON_FILE\\n\\n    def __init__(self, **kwargs):\\n        \\\"\\\"\\\"\\n        Constructor func, gets credentials and makes an instance.\\n        \\\"\\\"\\\"\\n        self.host = kwargs.get(\\\"host\\\") or \\\"\\\"\\n        self.user = kwargs.get(\\\"user\\\") or \\\"\\\"\\n        self.password = kwargs.get(\\\"password\\\") or \\\"\\\"\\n        self.port = kwargs.get(\\\"port\\\") or \\\"\\\"\\n\\n        self.client = clickhouse_connect.get_client(\\n            host=self.host, user=self.user, password=self.password, port=self.port\\n        )\\n\\n        self.query_str = \\\"\\\"\\\"SELECT created, event_time, event_name, af_sub1\\n            FROM analytics.appsflyer_export FINAL\\n            WHERE media_source = 'Popunder' \\n                AND created > {prev_last_created:datetime}\\n                AND event_name IN ('install', 'af_start_trial', 'af_subscribe', 'trial_renewal_cancelled')\\n            ORDER BY event_time DESC\\\"\\\"\\\"\\n\\n        # Check if the JSON file exists\\n        if os.path.exists(self.json_file_path):\\n            # Read the existing JSON file\\n            with open(self.json_file_path, \\\"r\\\", encoding=\\\"utf-8\\\") as file:\\n                stored_values = json.load(file)\\n                self.prev_last_created = datetime.fromisoformat(\\n                    stored_values.get(\\\"prev_last_created\\\", 0)\\n                )\\n        else:\\n            self.prev_last_created = datetime.now() - timedelta(weeks=1)\\n        self.logger.debug(\\\"Make an instance of %s class\\\", self.__class__.__name__)\\n\\n    def __del__(self):\\n        \\\"\\\"\\\"\\n        Destructor func, closes connection.\\n        \\\"\\\"\\\"\\n        self.client.close()\\n\\n    def fetch_new_events(self) -> pd.DataFrame:\\n        \\\"\\\"\\\"\\n        Fetches new events from ClickHouse DWH.\\n        \\\"\\\"\\\"\\n        parameters = {\\\"prev_last_created\\\": self.prev_last_created}\\n        result = self.client.query(self.query_str, parameters=parameters)\\n        df = pd.DataFrame(result.result_rows, columns=result.column_names)\\n        if df.empty:\\n            return pd.DataFrame()\\n        with open(self.json_file_path, \\\"w\\\", encoding=\\\"utf-8\\\") as file:\\n            json.dump({\\\"prev_last_created\\\": str(df[\\\"created\\\"].max())}, file)\\n        return df\";\n",
       "                var nbb_formatted_code = \"class ClickHouseConnector:\\n    \\\"\\\"\\\"Class to connect ClickHouse DWH and fetch events.\\\"\\\"\\\"\\n\\n    logger = get_cls_logger(__qualname__)\\n    json_file_path = cfg.JSON_FILE\\n\\n    def __init__(self, **kwargs):\\n        \\\"\\\"\\\"\\n        Constructor func, gets credentials and makes an instance.\\n        \\\"\\\"\\\"\\n        self.host = kwargs.get(\\\"host\\\") or \\\"\\\"\\n        self.user = kwargs.get(\\\"user\\\") or \\\"\\\"\\n        self.password = kwargs.get(\\\"password\\\") or \\\"\\\"\\n        self.port = kwargs.get(\\\"port\\\") or \\\"\\\"\\n\\n        self.client = clickhouse_connect.get_client(\\n            host=self.host, user=self.user, password=self.password, port=self.port\\n        )\\n\\n        self.query_str = \\\"\\\"\\\"SELECT created, event_time, event_name, af_sub1\\n            FROM analytics.appsflyer_export FINAL\\n            WHERE media_source = 'Popunder' \\n                AND created > {prev_last_created:datetime}\\n                AND event_name IN ('install', 'af_start_trial', 'af_subscribe', 'trial_renewal_cancelled')\\n            ORDER BY event_time DESC\\\"\\\"\\\"\\n\\n        # Check if the JSON file exists\\n        if os.path.exists(self.json_file_path):\\n            # Read the existing JSON file\\n            with open(self.json_file_path, \\\"r\\\", encoding=\\\"utf-8\\\") as file:\\n                stored_values = json.load(file)\\n                self.prev_last_created = datetime.fromisoformat(\\n                    stored_values.get(\\\"prev_last_created\\\", 0)\\n                )\\n        else:\\n            self.prev_last_created = datetime.now() - timedelta(weeks=1)\\n        self.logger.debug(\\\"Make an instance of %s class\\\", self.__class__.__name__)\\n\\n    def __del__(self):\\n        \\\"\\\"\\\"\\n        Destructor func, closes connection.\\n        \\\"\\\"\\\"\\n        self.client.close()\\n\\n    def fetch_new_events(self) -> pd.DataFrame:\\n        \\\"\\\"\\\"\\n        Fetches new events from ClickHouse DWH.\\n        \\\"\\\"\\\"\\n        parameters = {\\\"prev_last_created\\\": self.prev_last_created}\\n        result = self.client.query(self.query_str, parameters=parameters)\\n        df = pd.DataFrame(result.result_rows, columns=result.column_names)\\n        if df.empty:\\n            return pd.DataFrame()\\n        with open(self.json_file_path, \\\"w\\\", encoding=\\\"utf-8\\\") as file:\\n            json.dump({\\\"prev_last_created\\\": str(df[\\\"created\\\"].max())}, file)\\n        return df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ClickHouseConnector:\n",
    "    \"\"\"Class to connect ClickHouse DWH and fetch events.\"\"\"\n",
    "\n",
    "    logger = get_cls_logger(__qualname__)\n",
    "    json_file_path = cfg.JSON_FILE\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Constructor func, gets credentials and makes an instance.\n",
    "        \"\"\"\n",
    "        self.host = kwargs.get(\"host\") or \"\"\n",
    "        self.user = kwargs.get(\"user\") or \"\"\n",
    "        self.password = kwargs.get(\"password\") or \"\"\n",
    "        self.port = kwargs.get(\"port\") or \"\"\n",
    "\n",
    "        self.client = clickhouse_connect.get_client(\n",
    "            host=self.host, user=self.user, password=self.password, port=self.port\n",
    "        )\n",
    "\n",
    "        self.query_str = \"\"\"SELECT created, event_time, event_name, af_sub1\n",
    "            FROM analytics.appsflyer_export FINAL\n",
    "            WHERE media_source = 'Popunder' \n",
    "                AND created > {prev_last_created:datetime}\n",
    "                AND event_name IN ('install', 'af_start_trial', 'af_subscribe', 'trial_renewal_cancelled')\n",
    "            ORDER BY event_time DESC\"\"\"\n",
    "\n",
    "        # Check if the JSON file exists\n",
    "        if os.path.exists(self.json_file_path):\n",
    "            # Read the existing JSON file\n",
    "            with open(self.json_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                stored_values = json.load(file)\n",
    "                self.prev_last_created = datetime.fromisoformat(\n",
    "                    stored_values.get(\"prev_last_created\", 0)\n",
    "                )\n",
    "        else:\n",
    "            self.prev_last_created = datetime.now() - timedelta(weeks=1)\n",
    "        self.logger.debug(\"Make an instance of %s class\", self.__class__.__name__)\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"\n",
    "        Destructor func, closes connection.\n",
    "        \"\"\"\n",
    "        self.client.close()\n",
    "\n",
    "    def fetch_new_events(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Fetches new events from ClickHouse DWH.\n",
    "        \"\"\"\n",
    "        parameters = {\"prev_last_created\": self.prev_last_created}\n",
    "        result = self.client.query(self.query_str, parameters=parameters)\n",
    "        df = pd.DataFrame(result.result_rows, columns=result.column_names)\n",
    "        if df.empty:\n",
    "            return pd.DataFrame()\n",
    "        with open(self.json_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            json.dump({\"prev_last_created\": str(df[\"created\"].max())}, file)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a34e17b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"dwh = ClickHouseConnector(\\n    host=cfg.CLICKHOUSE_HOST,\\n    user=cfg.CLICKHOUSE_USER,\\n    password=cfg.CLICKHOUSE_PASS,\\n    port=cfg.CLICKHOUSE_PORT,\\n)\\n\\ndf = dwh.fetch_new_events()\\n\\ndel dwh\";\n",
       "                var nbb_formatted_code = \"dwh = ClickHouseConnector(\\n    host=cfg.CLICKHOUSE_HOST,\\n    user=cfg.CLICKHOUSE_USER,\\n    password=cfg.CLICKHOUSE_PASS,\\n    port=cfg.CLICKHOUSE_PORT,\\n)\\n\\ndf = dwh.fetch_new_events()\\n\\ndel dwh\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dwh = ClickHouseConnector(\n",
    "    host=cfg.CLICKHOUSE_HOST,\n",
    "    user=cfg.CLICKHOUSE_USER,\n",
    "    password=cfg.CLICKHOUSE_PASS,\n",
    "    port=cfg.CLICKHOUSE_PORT,\n",
    ")\n",
    "\n",
    "df = dwh.fetch_new_events()\n",
    "\n",
    "del dwh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a987aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created</th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_name</th>\n",
       "      <th>af_sub1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-04-16 16:30:01+00:00</td>\n",
       "      <td>2024-04-16 22:04:53</td>\n",
       "      <td>af_subscribe</td>\n",
       "      <td>be623gxj6hoqebl330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-04-16 16:30:01+00:00</td>\n",
       "      <td>2024-04-16 21:53:47</td>\n",
       "      <td>af_subscribe</td>\n",
       "      <td>5682bgxtw3zibwj2e0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-16 16:30:01+00:00</td>\n",
       "      <td>2024-04-16 21:28:23</td>\n",
       "      <td>af_subscribe</td>\n",
       "      <td>b2072gxj6yd3zi421a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-04-16 16:30:01+00:00</td>\n",
       "      <td>2024-04-16 19:21:29</td>\n",
       "      <td>af_subscribe</td>\n",
       "      <td>2ed62gxj6a6ghblaf4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-04-16 16:30:01+00:00</td>\n",
       "      <td>2024-04-16 18:47:49</td>\n",
       "      <td>af_subscribe</td>\n",
       "      <td>0f9c8gxdvslk28nf20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2024-04-16 16:30:01+00:00</td>\n",
       "      <td>2024-04-15 00:00:51</td>\n",
       "      <td>af_start_trial</td>\n",
       "      <td>87a45gxp2h9a108e5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>2024-04-16 16:30:01+00:00</td>\n",
       "      <td>2024-04-15 00:00:41</td>\n",
       "      <td>install</td>\n",
       "      <td>66eecgxp2h9gxvrec4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>2024-04-16 16:30:01+00:00</td>\n",
       "      <td>2024-04-15 00:00:34</td>\n",
       "      <td>trial_renewal_cancelled</td>\n",
       "      <td>f67f2gxp2a8p28n45b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>2024-04-16 16:30:01+00:00</td>\n",
       "      <td>2024-04-15 00:00:26</td>\n",
       "      <td>install</td>\n",
       "      <td>65fecgxp217fv8ne52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>2024-04-16 16:30:01+00:00</td>\n",
       "      <td>2024-04-15 00:00:24</td>\n",
       "      <td>install</td>\n",
       "      <td>87a45gxp2h9a108e5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1463 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created           event_time               event_name  \\\n",
       "0    2024-04-16 16:30:01+00:00  2024-04-16 22:04:53             af_subscribe   \n",
       "1    2024-04-16 16:30:01+00:00  2024-04-16 21:53:47             af_subscribe   \n",
       "2    2024-04-16 16:30:01+00:00  2024-04-16 21:28:23             af_subscribe   \n",
       "3    2024-04-16 16:30:01+00:00  2024-04-16 19:21:29             af_subscribe   \n",
       "4    2024-04-16 16:30:01+00:00  2024-04-16 18:47:49             af_subscribe   \n",
       "...                        ...                  ...                      ...   \n",
       "1458 2024-04-16 16:30:01+00:00  2024-04-15 00:00:51           af_start_trial   \n",
       "1459 2024-04-16 16:30:01+00:00  2024-04-15 00:00:41                  install   \n",
       "1460 2024-04-16 16:30:01+00:00  2024-04-15 00:00:34  trial_renewal_cancelled   \n",
       "1461 2024-04-16 16:30:01+00:00  2024-04-15 00:00:26                  install   \n",
       "1462 2024-04-16 16:30:01+00:00  2024-04-15 00:00:24                  install   \n",
       "\n",
       "                 af_sub1  \n",
       "0     be623gxj6hoqebl330  \n",
       "1     5682bgxtw3zibwj2e0  \n",
       "2     b2072gxj6yd3zi421a  \n",
       "3     2ed62gxj6a6ghblaf4  \n",
       "4     0f9c8gxdvslk28nf20  \n",
       "...                  ...  \n",
       "1458   87a45gxp2h9a108e5  \n",
       "1459  66eecgxp2h9gxvrec4  \n",
       "1460  f67f2gxp2a8p28n45b  \n",
       "1461  65fecgxp217fv8ne52  \n",
       "1462   87a45gxp2h9a108e5  \n",
       "\n",
       "[1463 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# df[df[\\\"event_name\\\"].str.contains(\\\"start_trial\\\")]\\n# df[df[\\\"af_sub1\\\"] == \\\"483bfgxtwj652wj656\\\"]\\n# df[\\\"event_time\\\"] = pd.to_datetime(df[\\\"event_time\\\"])\\n# df[\\\"event_time\\\"] = df[\\\"event_time\\\"].dt.strftime(\\\"%Y-%m-%d %H:%M:%S\\\")\\ndf[:]\\n# df[\\\"created\\\"].drop_duplicates()\\n# df[\\\"created\\\"].max()\\n# filtered_df = df[df[\\\"event_time\\\"].dt.date == pd.to_datetime(\\\"2024-04-10\\\").date()]\\n# filtered_df[filtered_df[\\\"af_sub1\\\"] == \\\"e24cdgx9l1zci3yeb5\\\"]\\n# filtered_df = df.drop(columns=[\\\"created\\\", \\\"event_name\\\", \\\"af_sub1\\\"])\\n# duplicates = filtered_df[filtered_df.duplicated()]\\n# duplicates\\n# filtered_df.drop_duplicates()\";\n",
       "                var nbb_formatted_code = \"# df[df[\\\"event_name\\\"].str.contains(\\\"start_trial\\\")]\\n# df[df[\\\"af_sub1\\\"] == \\\"483bfgxtwj652wj656\\\"]\\n# df[\\\"event_time\\\"] = pd.to_datetime(df[\\\"event_time\\\"])\\n# df[\\\"event_time\\\"] = df[\\\"event_time\\\"].dt.strftime(\\\"%Y-%m-%d %H:%M:%S\\\")\\ndf[:]\\n# df[\\\"created\\\"].drop_duplicates()\\n# df[\\\"created\\\"].max()\\n# filtered_df = df[df[\\\"event_time\\\"].dt.date == pd.to_datetime(\\\"2024-04-10\\\").date()]\\n# filtered_df[filtered_df[\\\"af_sub1\\\"] == \\\"e24cdgx9l1zci3yeb5\\\"]\\n# filtered_df = df.drop(columns=[\\\"created\\\", \\\"event_name\\\", \\\"af_sub1\\\"])\\n# duplicates = filtered_df[filtered_df.duplicated()]\\n# duplicates\\n# filtered_df.drop_duplicates()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df[df[\"event_name\"].str.contains(\"start_trial\")]\n",
    "# df[df[\"af_sub1\"] == \"483bfgxtwj652wj656\"]\n",
    "# df[\"event_time\"] = pd.to_datetime(df[\"event_time\"])\n",
    "# df[\"event_time\"] = df[\"event_time\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "df[:]\n",
    "# df[\"created\"].drop_duplicates()\n",
    "# df[\"created\"].max()\n",
    "# filtered_df = df[df[\"event_time\"].dt.date == pd.to_datetime(\"2024-04-10\").date()]\n",
    "# filtered_df[filtered_df[\"af_sub1\"] == \"e24cdgx9l1zci3yeb5\"]\n",
    "# filtered_df = df.drop(columns=[\"created\", \"event_name\", \"af_sub1\"])\n",
    "# duplicates = filtered_df[filtered_df.duplicated()]\n",
    "# duplicates\n",
    "# filtered_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87c0c1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"from datetime import datetime\\n\\nCURRENT_DATE = datetime.now().strftime(\\\"%Y-%m-%d\\\")\\ncsv_file = CURRENT_DATE + \\\"-all.csv\\\"\\n# filtered_df.to_csv(csv_file)\";\n",
       "                var nbb_formatted_code = \"from datetime import datetime\\n\\nCURRENT_DATE = datetime.now().strftime(\\\"%Y-%m-%d\\\")\\ncsv_file = CURRENT_DATE + \\\"-all.csv\\\"\\n# filtered_df.to_csv(csv_file)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "CURRENT_DATE = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "csv_file = CURRENT_DATE + \"-all.csv\"\n",
    "# filtered_df.to_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "414422ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# !cat 2024-04-09-trials.csv\";\n",
       "                var nbb_formatted_code = \"# !cat 2024-04-09-trials.csv\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !cat 2024-04-09-trials.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e93f287f-e3a5-4aaa-b943-1da6b98b626b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class EventProcessor:\\n    \\\"\\\"\\\"Class for processing events.\\\"\\\"\\\"\\n\\n    BASE_URL = cfg.BASE_URL\\n    logger = get_cls_logger(__qualname__)\\n\\n    def __init__(self, **kwargs):\\n        \\\"\\\"\\\"\\n        Constructor func, gets events DataFrame and makes an instance.\\n        Trying to connect db or creating it if not exists.\\n        \\\"\\\"\\\"\\n        self.events_df = kwargs.get(\\\"events\\\")\\n        self.install = self.events_df[self.events_df[\\\"event_name\\\"] == \\\"install\\\"]\\n        self.trial = self.events_df[self.events_df[\\\"event_name\\\"] == \\\"af_start_trial\\\"]\\n        self.trial_cancelled = self.events_df[\\n            self.events_df[\\\"event_name\\\"] == \\\"trial_renewal_cancelled\\\"\\n        ]\\n        self.activation = self.events_df[self.events_df[\\\"event_name\\\"] == \\\"af_subscribe\\\"]\\n        self.logger.debug(\\\"Make an instance of %s class\\\", self.__class__.__name__)\\n\\n        self._create_db_if_not_exists()\\n\\n    def _create_db_if_not_exists(self):\\n        \\\"\\\"\\\"Create SQLite database if not exists.\\\"\\\"\\\"\\n        with sql.connect(cfg.DB_FILE, timeout=10) as con:\\n            db = con.cursor()\\n            try:\\n                self.logger.debug(\\\"Try to connect sqlite db\\\")\\n                db.execute(\\\"SELECT id FROM cachetab\\\")\\n            except sql.OperationalError:\\n                self.logger.debug(\\\"Sqlite db not exists, creating it from schema\\\")\\n                db.executescript(open(cfg.SCHEMA_FILE, \\\"rt\\\", encoding=\\\"utf-8\\\").read())\\n\\n    def _save_event_to_db(\\n        self, event_time: datetime, event_name: str, af_sub1: str\\n    ) -> bool:\\n        \\\"\\\"\\\"\\n        Save event to cache db.\\n        \\\"\\\"\\\"\\n        payload = {\\n            \\\"date\\\": datetime.now(),\\n            \\\"event_time\\\": event_time,\\n            \\\"event_name\\\": event_name,\\n            \\\"af_sub1\\\": af_sub1,\\n        }\\n\\n        with sql.connect(cfg.DB_FILE, timeout=10) as con:\\n            db = con.cursor()\\n            db.execute(\\n                \\\"SELECT id FROM cachetab WHERE af_sub1=:af_sub1 AND event_name=:event_name\\\",\\n                payload,\\n            )\\n\\n            if len(db.fetchall()) == 0:\\n                db.execute(\\n                    \\\"INSERT INTO cachetab (date, event_time, event_name, af_sub1)\\\"\\n                    \\\"values (:date, :event_time, :event_name, :af_sub1)\\\",\\n                    payload,\\n                )\\n                try:\\n                    con.commit()\\n                    self.logger.debug(\\n                        \\\"New record (%s) inserted in db\\\", payload[\\\"af_sub1\\\"]\\n                    )\\n                    return True\\n                except sql.OperationalError as err:\\n                    self.logger.error(\\\"OOps: Operational Error: %s\\\", err)\\n                    return False\\n            else:\\n                self.logger.debug(\\\"Record has already in db, skipping\\\")\\n                return False\\n\\n    def remove_event_from_db(self, af_sub1: str) -> None:\\n        \\\"\\\"\\\"\\n        Remove event from cache db.\\n        \\\"\\\"\\\"\\n        with sql.connect(cfg.DB_FILE, timeout=10) as con:\\n            db = con.cursor()\\n            db.execute(\\n                \\\"DELETE FROM cachetab WHERE af_sub1=:af_sub1\\\", {\\\"af_sub1\\\": af_sub1}\\n            )\\n            try:\\n                con.commit()\\n                self.logger.debug(\\\"Record (%s) removed from db\\\", af_sub1)\\n            except sql.OperationalError as err:\\n                self.logger.error(\\\"OOps: Operational Error: %s\\\", err)\\n                return\\n\\n    def _process_new_events(self, events_df: pd.DataFrame) -> pd.DataFrame:\\n        \\\"\\\"\\\"\\n        Process and save new events to cache db.\\n        \\\"\\\"\\\"\\n        new_events_df = pd.DataFrame(columns=events_df.columns)\\n        for index, row in events_df.iterrows():\\n            if self._save_event_to_db(\\n                row[\\\"event_time\\\"], row[\\\"event_name\\\"], row[\\\"af_sub1\\\"]\\n            ):\\n                new_events_df.loc[len(new_events_df)] = row\\n        return new_events_df\\n\\n    def remove_old_events(self):\\n        \\\"\\\"\\\"\\n        Remove old events from cache db.\\n        \\\"\\\"\\\"\\n        week_ago = datetime.now() - timedelta(weeks=1)\\n        with sql.connect(cfg.DB_FILE, timeout=10) as con:\\n            db = con.cursor()\\n            db.execute(\\n                \\\"DELETE FROM cachetab WHERE event_time < :week_ago\\\",\\n                {\\\"week_ago\\\": week_ago},\\n            )\\n            try:\\n                con.commit()\\n                self.logger.debug(\\\"Old records removed from db\\\")\\n            except sql.OperationalError as err:\\n                self.logger.error(\\\"OOps: Operational Error: %s\\\", err)\\n                return\\n\\n    def process_install_events(self):\\n        \\\"\\\"\\\"\\n        Process install events.\\n        \\\"\\\"\\\"\\n        self.install = self._process_new_events(self.install)\\n        self.install_requests()\\n\\n    def process_trial_events(self):\\n        \\\"\\\"\\\"\\n        Process trial events.\\n        \\\"\\\"\\\"\\n        self.trial = self._process_new_events(self.trial)\\n        self.trial_requests()\\n\\n    def process_cancelled_trial_events(self):\\n        \\\"\\\"\\\"\\n        Process cancelled trial events.\\n        \\\"\\\"\\\"\\n        self.trial_cancelled = self._process_new_events(self.trial_cancelled)\\n        self.cancel_trial_requests()\\n\\n    def process_activation_events(self):\\n        \\\"\\\"\\\"\\n        Process activation events.\\n        \\\"\\\"\\\"\\n        self.activation = self._process_new_events(self.activation)\\n        self.activation_requests()\\n\\n    def install_requests(self):\\n        \\\"\\\"\\\"\\n        Send requests for install events.\\n        \\\"\\\"\\\"\\n        self.send_event_requests(\\\"install\\\", \\\"install\\\", 1)\\n\\n    def activation_requests(self):\\n        \\\"\\\"\\\"\\n        Send requests for activation events.\\n        \\\"\\\"\\\"\\n        self.send_event_requests(\\\"activation\\\", \\\"trial_converted\\\", 4)\\n\\n    def trial_requests(self):\\n        \\\"\\\"\\\"\\n        Send requests for trial events.\\n        \\\"\\\"\\\"\\n        self.send_event_requests(\\\"trial\\\", \\\"trial_started\\\", 2)\\n\\n    def cancel_trial_requests(self):\\n        \\\"\\\"\\\"\\n        Send requests for cancelled trial events.\\n        \\\"\\\"\\\"\\n        self.send_event_requests(\\\"trial_cancelled\\\", \\\"trial_renewal_cancelled\\\", 6)\\n\\n    def send_event_requests(self, event_name, event_status, event_number):\\n        \\\"\\\"\\\"\\n        Send requests for specified event.\\n        \\\"\\\"\\\"\\n        events_df = getattr(self, event_name)\\n        if events_df.shape[0] == 0:\\n            return\\n        url = self.BASE_URL\\n        for af_sub1 in events_df[\\\"af_sub1\\\"]:\\n            params = [\\n                [\\\"cnv_id\\\", af_sub1],\\n                [\\\"cnv_status\\\", event_status],\\n                [f\\\"event{event_number}\\\", 1],\\n            ]\\n            response, error = self._requests_call(\\\"GET\\\", url=url, params=params)\\n            if error is not None:\\n                self.logger.error(\\n                    \\\"Error while transmiting event (%s): %s\\\", af_sub1, error\\n                )\\n                continue\\n\\n    def _requests_call(self, verb: str, url: str, params=None, **kwargs) -> tuple:\\n        \\\"\\\"\\\"\\n        Wraping func for requests with errors handling.\\n\\n        :param verb:\\n            str Method of request ``get`` or ``post``.\\n        :param url:\\n            str URL to connect.\\n        :return:\\n            Returns a tuple of response object and error.\\n            If an error occurs, the response will be empty\\n            and vice versa otherwise.\\n        \\\"\\\"\\\"\\n        r: object = None\\n        error: str = None\\n        retries: int = cfg.RETRIES  # default 10\\n        delay: int = cfg.DELAY  # default 6\\n\\n        for retry in range(retries):\\n            try:\\n                self.logger.debug(\\\"Try %s request %s\\\", verb, url)\\n                r = requests.request(verb, url, params=params)\\n                r.raise_for_status()\\n                self.logger.debug(\\n                    \\\"Get answer with status code: %s %s\\\", r.status_code, r.reason\\n                )\\n                return r, error\\n            except requests.exceptions.HTTPError as errh:\\n                self.logger.error(\\\"Http Error: %s\\\", errh)\\n                error = errh\\n                self.logger.debug(\\n                    \\\"Don't give up! Trying to reconnect, retry %s of %s\\\",\\n                    retry + 1,\\n                    retries,\\n                )\\n                time.sleep(delay)\\n            except requests.exceptions.ConnectionError as errc:\\n                self.logger.error(\\\"Connection Error: %s\\\", errc)\\n                error = errc\\n                self.logger.debug(\\n                    \\\"Don't give up! Trying to reconnect, retry %s of %s\\\",\\n                    retry + 1,\\n                    retries,\\n                )\\n                time.sleep(delay)\\n            except requests.exceptions.Timeout as errt:\\n                self.logger.error(\\\"Timeout Error: %s\\\", errt)\\n                error = errt\\n                self.logger.debug(\\n                    \\\"Don't give up! Trying to reconnect, retry %s of %s\\\",\\n                    retry + 1,\\n                    retries,\\n                )\\n                time.sleep(delay)\\n            except requests.exceptions.RequestException as err:\\n                self.logger.error(\\\"OOps: Unexpected Error: %s\\\", err)\\n                error = err\\n                self.logger.debug(\\n                    \\\"Don't give up! Trying to reconnect, retry %s of %s\\\",\\n                    retry + 1,\\n                    retries,\\n                )\\n                time.sleep(delay)\\n\\n        return r, error\";\n",
       "                var nbb_formatted_code = \"class EventProcessor:\\n    \\\"\\\"\\\"Class for processing events.\\\"\\\"\\\"\\n\\n    BASE_URL = cfg.BASE_URL\\n    logger = get_cls_logger(__qualname__)\\n\\n    def __init__(self, **kwargs):\\n        \\\"\\\"\\\"\\n        Constructor func, gets events DataFrame and makes an instance.\\n        Trying to connect db or creating it if not exists.\\n        \\\"\\\"\\\"\\n        self.events_df = kwargs.get(\\\"events\\\")\\n        self.install = self.events_df[self.events_df[\\\"event_name\\\"] == \\\"install\\\"]\\n        self.trial = self.events_df[self.events_df[\\\"event_name\\\"] == \\\"af_start_trial\\\"]\\n        self.trial_cancelled = self.events_df[\\n            self.events_df[\\\"event_name\\\"] == \\\"trial_renewal_cancelled\\\"\\n        ]\\n        self.activation = self.events_df[self.events_df[\\\"event_name\\\"] == \\\"af_subscribe\\\"]\\n        self.logger.debug(\\\"Make an instance of %s class\\\", self.__class__.__name__)\\n\\n        self._create_db_if_not_exists()\\n\\n    def _create_db_if_not_exists(self):\\n        \\\"\\\"\\\"Create SQLite database if not exists.\\\"\\\"\\\"\\n        with sql.connect(cfg.DB_FILE, timeout=10) as con:\\n            db = con.cursor()\\n            try:\\n                self.logger.debug(\\\"Try to connect sqlite db\\\")\\n                db.execute(\\\"SELECT id FROM cachetab\\\")\\n            except sql.OperationalError:\\n                self.logger.debug(\\\"Sqlite db not exists, creating it from schema\\\")\\n                db.executescript(open(cfg.SCHEMA_FILE, \\\"rt\\\", encoding=\\\"utf-8\\\").read())\\n\\n    def _save_event_to_db(\\n        self, event_time: datetime, event_name: str, af_sub1: str\\n    ) -> bool:\\n        \\\"\\\"\\\"\\n        Save event to cache db.\\n        \\\"\\\"\\\"\\n        payload = {\\n            \\\"date\\\": datetime.now(),\\n            \\\"event_time\\\": event_time,\\n            \\\"event_name\\\": event_name,\\n            \\\"af_sub1\\\": af_sub1,\\n        }\\n\\n        with sql.connect(cfg.DB_FILE, timeout=10) as con:\\n            db = con.cursor()\\n            db.execute(\\n                \\\"SELECT id FROM cachetab WHERE af_sub1=:af_sub1 AND event_name=:event_name\\\",\\n                payload,\\n            )\\n\\n            if len(db.fetchall()) == 0:\\n                db.execute(\\n                    \\\"INSERT INTO cachetab (date, event_time, event_name, af_sub1)\\\"\\n                    \\\"values (:date, :event_time, :event_name, :af_sub1)\\\",\\n                    payload,\\n                )\\n                try:\\n                    con.commit()\\n                    self.logger.debug(\\n                        \\\"New record (%s) inserted in db\\\", payload[\\\"af_sub1\\\"]\\n                    )\\n                    return True\\n                except sql.OperationalError as err:\\n                    self.logger.error(\\\"OOps: Operational Error: %s\\\", err)\\n                    return False\\n            else:\\n                self.logger.debug(\\\"Record has already in db, skipping\\\")\\n                return False\\n\\n    def remove_event_from_db(self, af_sub1: str) -> None:\\n        \\\"\\\"\\\"\\n        Remove event from cache db.\\n        \\\"\\\"\\\"\\n        with sql.connect(cfg.DB_FILE, timeout=10) as con:\\n            db = con.cursor()\\n            db.execute(\\n                \\\"DELETE FROM cachetab WHERE af_sub1=:af_sub1\\\", {\\\"af_sub1\\\": af_sub1}\\n            )\\n            try:\\n                con.commit()\\n                self.logger.debug(\\\"Record (%s) removed from db\\\", af_sub1)\\n            except sql.OperationalError as err:\\n                self.logger.error(\\\"OOps: Operational Error: %s\\\", err)\\n                return\\n\\n    def _process_new_events(self, events_df: pd.DataFrame) -> pd.DataFrame:\\n        \\\"\\\"\\\"\\n        Process and save new events to cache db.\\n        \\\"\\\"\\\"\\n        new_events_df = pd.DataFrame(columns=events_df.columns)\\n        for index, row in events_df.iterrows():\\n            if self._save_event_to_db(\\n                row[\\\"event_time\\\"], row[\\\"event_name\\\"], row[\\\"af_sub1\\\"]\\n            ):\\n                new_events_df.loc[len(new_events_df)] = row\\n        return new_events_df\\n\\n    def remove_old_events(self):\\n        \\\"\\\"\\\"\\n        Remove old events from cache db.\\n        \\\"\\\"\\\"\\n        week_ago = datetime.now() - timedelta(weeks=1)\\n        with sql.connect(cfg.DB_FILE, timeout=10) as con:\\n            db = con.cursor()\\n            db.execute(\\n                \\\"DELETE FROM cachetab WHERE event_time < :week_ago\\\",\\n                {\\\"week_ago\\\": week_ago},\\n            )\\n            try:\\n                con.commit()\\n                self.logger.debug(\\\"Old records removed from db\\\")\\n            except sql.OperationalError as err:\\n                self.logger.error(\\\"OOps: Operational Error: %s\\\", err)\\n                return\\n\\n    def process_install_events(self):\\n        \\\"\\\"\\\"\\n        Process install events.\\n        \\\"\\\"\\\"\\n        self.install = self._process_new_events(self.install)\\n        self.install_requests()\\n\\n    def process_trial_events(self):\\n        \\\"\\\"\\\"\\n        Process trial events.\\n        \\\"\\\"\\\"\\n        self.trial = self._process_new_events(self.trial)\\n        self.trial_requests()\\n\\n    def process_cancelled_trial_events(self):\\n        \\\"\\\"\\\"\\n        Process cancelled trial events.\\n        \\\"\\\"\\\"\\n        self.trial_cancelled = self._process_new_events(self.trial_cancelled)\\n        self.cancel_trial_requests()\\n\\n    def process_activation_events(self):\\n        \\\"\\\"\\\"\\n        Process activation events.\\n        \\\"\\\"\\\"\\n        self.activation = self._process_new_events(self.activation)\\n        self.activation_requests()\\n\\n    def install_requests(self):\\n        \\\"\\\"\\\"\\n        Send requests for install events.\\n        \\\"\\\"\\\"\\n        self.send_event_requests(\\\"install\\\", \\\"install\\\", 1)\\n\\n    def activation_requests(self):\\n        \\\"\\\"\\\"\\n        Send requests for activation events.\\n        \\\"\\\"\\\"\\n        self.send_event_requests(\\\"activation\\\", \\\"trial_converted\\\", 4)\\n\\n    def trial_requests(self):\\n        \\\"\\\"\\\"\\n        Send requests for trial events.\\n        \\\"\\\"\\\"\\n        self.send_event_requests(\\\"trial\\\", \\\"trial_started\\\", 2)\\n\\n    def cancel_trial_requests(self):\\n        \\\"\\\"\\\"\\n        Send requests for cancelled trial events.\\n        \\\"\\\"\\\"\\n        self.send_event_requests(\\\"trial_cancelled\\\", \\\"trial_renewal_cancelled\\\", 6)\\n\\n    def send_event_requests(self, event_name, event_status, event_number):\\n        \\\"\\\"\\\"\\n        Send requests for specified event.\\n        \\\"\\\"\\\"\\n        events_df = getattr(self, event_name)\\n        if events_df.shape[0] == 0:\\n            return\\n        url = self.BASE_URL\\n        for af_sub1 in events_df[\\\"af_sub1\\\"]:\\n            params = [\\n                [\\\"cnv_id\\\", af_sub1],\\n                [\\\"cnv_status\\\", event_status],\\n                [f\\\"event{event_number}\\\", 1],\\n            ]\\n            response, error = self._requests_call(\\\"GET\\\", url=url, params=params)\\n            if error is not None:\\n                self.logger.error(\\n                    \\\"Error while transmiting event (%s): %s\\\", af_sub1, error\\n                )\\n                continue\\n\\n    def _requests_call(self, verb: str, url: str, params=None, **kwargs) -> tuple:\\n        \\\"\\\"\\\"\\n        Wraping func for requests with errors handling.\\n\\n        :param verb:\\n            str Method of request ``get`` or ``post``.\\n        :param url:\\n            str URL to connect.\\n        :return:\\n            Returns a tuple of response object and error.\\n            If an error occurs, the response will be empty\\n            and vice versa otherwise.\\n        \\\"\\\"\\\"\\n        r: object = None\\n        error: str = None\\n        retries: int = cfg.RETRIES  # default 10\\n        delay: int = cfg.DELAY  # default 6\\n\\n        for retry in range(retries):\\n            try:\\n                self.logger.debug(\\\"Try %s request %s\\\", verb, url)\\n                r = requests.request(verb, url, params=params)\\n                r.raise_for_status()\\n                self.logger.debug(\\n                    \\\"Get answer with status code: %s %s\\\", r.status_code, r.reason\\n                )\\n                return r, error\\n            except requests.exceptions.HTTPError as errh:\\n                self.logger.error(\\\"Http Error: %s\\\", errh)\\n                error = errh\\n                self.logger.debug(\\n                    \\\"Don't give up! Trying to reconnect, retry %s of %s\\\",\\n                    retry + 1,\\n                    retries,\\n                )\\n                time.sleep(delay)\\n            except requests.exceptions.ConnectionError as errc:\\n                self.logger.error(\\\"Connection Error: %s\\\", errc)\\n                error = errc\\n                self.logger.debug(\\n                    \\\"Don't give up! Trying to reconnect, retry %s of %s\\\",\\n                    retry + 1,\\n                    retries,\\n                )\\n                time.sleep(delay)\\n            except requests.exceptions.Timeout as errt:\\n                self.logger.error(\\\"Timeout Error: %s\\\", errt)\\n                error = errt\\n                self.logger.debug(\\n                    \\\"Don't give up! Trying to reconnect, retry %s of %s\\\",\\n                    retry + 1,\\n                    retries,\\n                )\\n                time.sleep(delay)\\n            except requests.exceptions.RequestException as err:\\n                self.logger.error(\\\"OOps: Unexpected Error: %s\\\", err)\\n                error = err\\n                self.logger.debug(\\n                    \\\"Don't give up! Trying to reconnect, retry %s of %s\\\",\\n                    retry + 1,\\n                    retries,\\n                )\\n                time.sleep(delay)\\n\\n        return r, error\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class EventProcessor:\n",
    "    \"\"\"Class for processing events.\"\"\"\n",
    "\n",
    "    BASE_URL = cfg.BASE_URL\n",
    "    logger = get_cls_logger(__qualname__)\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Constructor func, gets events DataFrame and makes an instance.\n",
    "        Trying to connect db or creating it if not exists.\n",
    "        \"\"\"\n",
    "        self.events_df = kwargs.get(\"events\")\n",
    "        self.install = self.events_df[self.events_df[\"event_name\"] == \"install\"]\n",
    "        self.trial = self.events_df[self.events_df[\"event_name\"] == \"af_start_trial\"]\n",
    "        self.trial_cancelled = self.events_df[\n",
    "            self.events_df[\"event_name\"] == \"trial_renewal_cancelled\"\n",
    "        ]\n",
    "        self.activation = self.events_df[self.events_df[\"event_name\"] == \"af_subscribe\"]\n",
    "        self.logger.debug(\"Make an instance of %s class\", self.__class__.__name__)\n",
    "\n",
    "        self._create_db_if_not_exists()\n",
    "\n",
    "    def _create_db_if_not_exists(self):\n",
    "        \"\"\"Create SQLite database if not exists.\"\"\"\n",
    "        with sql.connect(cfg.DB_FILE, timeout=10) as con:\n",
    "            db = con.cursor()\n",
    "            try:\n",
    "                self.logger.debug(\"Try to connect sqlite db\")\n",
    "                db.execute(\"SELECT id FROM cachetab\")\n",
    "            except sql.OperationalError:\n",
    "                self.logger.debug(\"Sqlite db not exists, creating it from schema\")\n",
    "                db.executescript(open(cfg.SCHEMA_FILE, \"rt\", encoding=\"utf-8\").read())\n",
    "\n",
    "    def _save_event_to_db(\n",
    "        self, event_time: datetime, event_name: str, af_sub1: str\n",
    "    ) -> bool:\n",
    "        \"\"\"\n",
    "        Save event to cache db.\n",
    "        \"\"\"\n",
    "        payload = {\n",
    "            \"date\": datetime.now(),\n",
    "            \"event_time\": event_time,\n",
    "            \"event_name\": event_name,\n",
    "            \"af_sub1\": af_sub1,\n",
    "        }\n",
    "\n",
    "        with sql.connect(cfg.DB_FILE, timeout=10) as con:\n",
    "            db = con.cursor()\n",
    "            db.execute(\n",
    "                \"SELECT id FROM cachetab WHERE af_sub1=:af_sub1 AND event_name=:event_name\",\n",
    "                payload,\n",
    "            )\n",
    "\n",
    "            if len(db.fetchall()) == 0:\n",
    "                db.execute(\n",
    "                    \"INSERT INTO cachetab (date, event_time, event_name, af_sub1)\"\n",
    "                    \"values (:date, :event_time, :event_name, :af_sub1)\",\n",
    "                    payload,\n",
    "                )\n",
    "                try:\n",
    "                    con.commit()\n",
    "                    self.logger.debug(\n",
    "                        \"New record (%s) inserted in db\", payload[\"af_sub1\"]\n",
    "                    )\n",
    "                    return True\n",
    "                except sql.OperationalError as err:\n",
    "                    self.logger.error(\"OOps: Operational Error: %s\", err)\n",
    "                    return False\n",
    "            else:\n",
    "                self.logger.debug(\"Record has already in db, skipping\")\n",
    "                return False\n",
    "\n",
    "    def remove_event_from_db(self, af_sub1: str) -> None:\n",
    "        \"\"\"\n",
    "        Remove event from cache db.\n",
    "        \"\"\"\n",
    "        with sql.connect(cfg.DB_FILE, timeout=10) as con:\n",
    "            db = con.cursor()\n",
    "            db.execute(\n",
    "                \"DELETE FROM cachetab WHERE af_sub1=:af_sub1\", {\"af_sub1\": af_sub1}\n",
    "            )\n",
    "            try:\n",
    "                con.commit()\n",
    "                self.logger.debug(\"Record (%s) removed from db\", af_sub1)\n",
    "            except sql.OperationalError as err:\n",
    "                self.logger.error(\"OOps: Operational Error: %s\", err)\n",
    "                return\n",
    "\n",
    "    def _process_new_events(self, events_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Process and save new events to cache db.\n",
    "        \"\"\"\n",
    "        new_events_df = pd.DataFrame(columns=events_df.columns)\n",
    "        for index, row in events_df.iterrows():\n",
    "            if self._save_event_to_db(\n",
    "                row[\"event_time\"], row[\"event_name\"], row[\"af_sub1\"]\n",
    "            ):\n",
    "                new_events_df.loc[len(new_events_df)] = row\n",
    "        return new_events_df\n",
    "\n",
    "    def remove_old_events(self):\n",
    "        \"\"\"\n",
    "        Remove old events from cache db.\n",
    "        \"\"\"\n",
    "        week_ago = datetime.now() - timedelta(weeks=1)\n",
    "        with sql.connect(cfg.DB_FILE, timeout=10) as con:\n",
    "            db = con.cursor()\n",
    "            db.execute(\n",
    "                \"DELETE FROM cachetab WHERE event_time < :week_ago\",\n",
    "                {\"week_ago\": week_ago},\n",
    "            )\n",
    "            try:\n",
    "                con.commit()\n",
    "                self.logger.debug(\"Old records removed from db\")\n",
    "            except sql.OperationalError as err:\n",
    "                self.logger.error(\"OOps: Operational Error: %s\", err)\n",
    "                return\n",
    "\n",
    "    def process_install_events(self):\n",
    "        \"\"\"\n",
    "        Process install events.\n",
    "        \"\"\"\n",
    "        self.install = self._process_new_events(self.install)\n",
    "        self.install_requests()\n",
    "\n",
    "    def process_trial_events(self):\n",
    "        \"\"\"\n",
    "        Process trial events.\n",
    "        \"\"\"\n",
    "        self.trial = self._process_new_events(self.trial)\n",
    "        self.trial_requests()\n",
    "\n",
    "    def process_cancelled_trial_events(self):\n",
    "        \"\"\"\n",
    "        Process cancelled trial events.\n",
    "        \"\"\"\n",
    "        self.trial_cancelled = self._process_new_events(self.trial_cancelled)\n",
    "        self.cancel_trial_requests()\n",
    "\n",
    "    def process_activation_events(self):\n",
    "        \"\"\"\n",
    "        Process activation events.\n",
    "        \"\"\"\n",
    "        self.activation = self._process_new_events(self.activation)\n",
    "        self.activation_requests()\n",
    "\n",
    "    def install_requests(self):\n",
    "        \"\"\"\n",
    "        Send requests for install events.\n",
    "        \"\"\"\n",
    "        self.send_event_requests(\"install\", \"install\", 1)\n",
    "\n",
    "    def activation_requests(self):\n",
    "        \"\"\"\n",
    "        Send requests for activation events.\n",
    "        \"\"\"\n",
    "        self.send_event_requests(\"activation\", \"trial_converted\", 4)\n",
    "\n",
    "    def trial_requests(self):\n",
    "        \"\"\"\n",
    "        Send requests for trial events.\n",
    "        \"\"\"\n",
    "        self.send_event_requests(\"trial\", \"trial_started\", 2)\n",
    "\n",
    "    def cancel_trial_requests(self):\n",
    "        \"\"\"\n",
    "        Send requests for cancelled trial events.\n",
    "        \"\"\"\n",
    "        self.send_event_requests(\"trial_cancelled\", \"trial_renewal_cancelled\", 6)\n",
    "\n",
    "    def send_event_requests(self, event_name, event_status, event_number):\n",
    "        \"\"\"\n",
    "        Send requests for specified event.\n",
    "        \"\"\"\n",
    "        events_df = getattr(self, event_name)\n",
    "        if events_df.shape[0] == 0:\n",
    "            return\n",
    "        url = self.BASE_URL\n",
    "        for af_sub1 in events_df[\"af_sub1\"]:\n",
    "            params = [\n",
    "                [\"cnv_id\", af_sub1],\n",
    "                [\"cnv_status\", event_status],\n",
    "                [f\"event{event_number}\", 1],\n",
    "            ]\n",
    "            response, error = self._requests_call(\"GET\", url=url, params=params)\n",
    "            if error is not None:\n",
    "                self.logger.error(\n",
    "                    \"Error while transmiting event (%s): %s\", af_sub1, error\n",
    "                )\n",
    "                continue\n",
    "\n",
    "    def _requests_call(self, verb: str, url: str, params=None, **kwargs) -> tuple:\n",
    "        \"\"\"\n",
    "        Wraping func for requests with errors handling.\n",
    "\n",
    "        :param verb:\n",
    "            str Method of request ``get`` or ``post``.\n",
    "        :param url:\n",
    "            str URL to connect.\n",
    "        :return:\n",
    "            Returns a tuple of response object and error.\n",
    "            If an error occurs, the response will be empty\n",
    "            and vice versa otherwise.\n",
    "        \"\"\"\n",
    "        r: object = None\n",
    "        error: str = None\n",
    "        retries: int = cfg.RETRIES  # default 10\n",
    "        delay: int = cfg.DELAY  # default 6\n",
    "\n",
    "        for retry in range(retries):\n",
    "            try:\n",
    "                self.logger.debug(\"Try %s request %s\", verb, url)\n",
    "                r = requests.request(verb, url, params=params)\n",
    "                r.raise_for_status()\n",
    "                self.logger.debug(\n",
    "                    \"Get answer with status code: %s %s\", r.status_code, r.reason\n",
    "                )\n",
    "                return r, error\n",
    "            except requests.exceptions.HTTPError as errh:\n",
    "                self.logger.error(\"Http Error: %s\", errh)\n",
    "                error = errh\n",
    "                self.logger.debug(\n",
    "                    \"Don't give up! Trying to reconnect, retry %s of %s\",\n",
    "                    retry + 1,\n",
    "                    retries,\n",
    "                )\n",
    "                time.sleep(delay)\n",
    "            except requests.exceptions.ConnectionError as errc:\n",
    "                self.logger.error(\"Connection Error: %s\", errc)\n",
    "                error = errc\n",
    "                self.logger.debug(\n",
    "                    \"Don't give up! Trying to reconnect, retry %s of %s\",\n",
    "                    retry + 1,\n",
    "                    retries,\n",
    "                )\n",
    "                time.sleep(delay)\n",
    "            except requests.exceptions.Timeout as errt:\n",
    "                self.logger.error(\"Timeout Error: %s\", errt)\n",
    "                error = errt\n",
    "                self.logger.debug(\n",
    "                    \"Don't give up! Trying to reconnect, retry %s of %s\",\n",
    "                    retry + 1,\n",
    "                    retries,\n",
    "                )\n",
    "                time.sleep(delay)\n",
    "            except requests.exceptions.RequestException as err:\n",
    "                self.logger.error(\"OOps: Unexpected Error: %s\", err)\n",
    "                error = err\n",
    "                self.logger.debug(\n",
    "                    \"Don't give up! Trying to reconnect, retry %s of %s\",\n",
    "                    retry + 1,\n",
    "                    retries,\n",
    "                )\n",
    "                time.sleep(delay)\n",
    "\n",
    "        return r, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08206e3a-9a16-4224-b72b-e9cfaa3556b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"if not df.empty:\\n    evs = EventProcessor(events=df)\\n\\n    evs.process_install_events()\\n    evs.process_activation_events()\\n    evs.process_trial_events()\\n    evs.process_cancelled_trial_events()\\n\\n    evs.remove_old_events()\\n\\n#     evs.install_requests()\\n#     evs.trial_requests()\\n#     evs.activation_requests()\\n#     evs.process_new_trials()\\n#     evs.process_cancelled_trials()\\n#     evs.cancel_trial_requests()\";\n",
       "                var nbb_formatted_code = \"if not df.empty:\\n    evs = EventProcessor(events=df)\\n\\n    evs.process_install_events()\\n    evs.process_activation_events()\\n    evs.process_trial_events()\\n    evs.process_cancelled_trial_events()\\n\\n    evs.remove_old_events()\\n\\n#     evs.install_requests()\\n#     evs.trial_requests()\\n#     evs.activation_requests()\\n#     evs.process_new_trials()\\n#     evs.process_cancelled_trials()\\n#     evs.cancel_trial_requests()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not df.empty:\n",
    "    evs = EventProcessor(events=df)\n",
    "\n",
    "    evs.process_install_events()\n",
    "    evs.process_activation_events()\n",
    "    evs.process_trial_events()\n",
    "    evs.process_cancelled_trial_events()\n",
    "\n",
    "    evs.remove_old_events()\n",
    "\n",
    "#     evs.install_requests()\n",
    "#     evs.trial_requests()\n",
    "#     evs.activation_requests()\n",
    "#     evs.process_new_trials()\n",
    "#     evs.process_cancelled_trials()\n",
    "#     evs.cancel_trial_requests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2dc81e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
